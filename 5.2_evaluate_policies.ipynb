{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of Targeting Policies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    'C:/Users/julia/OneDrive - Humboldt-Universitaet zu Berlin, CMS/Desktop_alt/thesis/code/treatment-learn')\n",
    "from treatlearn.policy import bayesian_targeting_policy\n",
    "from treatlearn.evaluation import transformed_outcome_loss, expected_policy_profit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confirm the path to the actual data and the path where the model results are saved."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import rc\n",
    "# rc('font',**{'family':'serif','serif':['cm']})\n",
    "# ## for Palatino and other serif fonts use:\n",
    "# #rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# rc('text', usetex=False)\n",
    "# #matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "# matplotlib.pyplot.title(r'ABC123 vs $\\mathrm{ABC123}^{123}$')\n",
    "#\n",
    "# plt.rc('text.latex', preamble=r'\\usepackage{underscore}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results of different runs, some after scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5.2 All models, without scaling\n",
    "DATA_PATH = \"data/fashionB_clean_nonlinear.csv\"\n",
    "RESULT_PATH = \"prediction_test_results_5.2\"\n",
    "#RESULT_PATH = \"oracle_prediction_test_targeting\" # for scaled predictions after selection\n",
    "predictions = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_test = [fold for fold in predictions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#5.3. Regularization: 50 folds with CATE Scaling\n",
    "RESULT_PATH = \"prediction_test_scaled_cv_CATE\"\n",
    "predictions_test = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_test = [fold for fold in predictions_test]\n",
    "RESULT_PATH = \"prediction_train_scaled_cv_CATE\"\n",
    "predictions_train = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_train = [fold for fold in predictions_train]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#5.3. Regularization: 50 folds without CATE Scaling\n",
    "RESULT_PATH = \"prediction_test_cv\"\n",
    "predictions_test = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_test = [fold for fold in predictions_test]\n",
    "RESULT_PATH = \"prediction_train_cv\"\n",
    "predictions_train = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_train = [fold for fold in predictions_train]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#5.3. Regularization: 50 folds with Oracle Scaling, XBCF shifted beforehand\n",
    "RESULT_PATH = \"prediction_test_oracle_cv\"\n",
    "predictions_test = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_test = [fold for fold in predictions_test]\n",
    "RESULT_PATH = \"prediction_train_oracle_cv\"\n",
    "predictions_train = np.load(f\"results/{RESULT_PATH}.npy\", allow_pickle=True)\n",
    "predictions_train = [fold for fold in predictions_train]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/fashionB_clean_nonlinear.csv\"\n",
    "# Load data\n",
    "X = pd.read_csv(DATA_PATH)\n",
    "\n",
    "c = X.pop('converted').to_numpy()\n",
    "g = X.pop('TREATMENT').to_numpy()\n",
    "y = X.pop('checkoutAmount').to_numpy()\n",
    "tau_conversion = X.pop('TREATMENT_EFFECT_CONVERSION')\n",
    "tau_basket = X.pop('TREATMENT_EFFECT_BASKET')\n",
    "tau_response = X.pop('TREATMENT_EFFECT_RESPONSE').to_numpy()  #added\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "today"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MARGIN_RATIO = 0.3\n",
    "OFFER_COST = 10\n",
    "from helper import *\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Regularization Policy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For Oracle Evaluation: Simulation with Grid of Lambdas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = 0.5\n",
    "step = 0.01\n",
    "\n",
    "float_range_array = np.arange(start, stop, step)  #.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Policy with Oracle setting\n",
    "eval_profit_reg_left = []\n",
    "for outcome_dict in tqdm(predictions_test):\n",
    "    #outcome_dict_train = prediction_dict[\"train\"]\n",
    "    #outcome_dict = prediction_dict[\"test\"]\n",
    "\n",
    "    for gamma in float_range_array:\n",
    "        # Calculate policy decision\n",
    "\n",
    "        policy_dict, errors_reg = calc_bayesian_uncertainty_policy(\n",
    "            treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "            pi_dict=outcome_dict['prediction_intervals'],\n",
    "            conversion_dict=outcome_dict[\"conversion\"],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST, gamma=gamma,\n",
    "            tail='left', calc_error=True, y=y[outcome_dict[\"idx\"]],\n",
    "            g=g[outcome_dict[\"idx\"]], tau_true=tau_response[outcome_dict[\"idx\"]])\n",
    "        #policy_dict.update(reg_policy)\n",
    "\n",
    "        profit = calc_policy_profit(\n",
    "            policy_dict=policy_dict,\n",
    "            y_true=y[outcome_dict[\"idx\"]], c_true=c[outcome_dict[\"idx\"]], g=g[outcome_dict[\"idx\"]],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST)\n",
    "        profit.update(errors_reg)\n",
    "        eval_profit_reg_left.append(profit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(f\"results/eval_profit_oracle_error.npy\", eval_profit_reg_left, allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Empirical tuning of lambda (here: gamma), returns RSME:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_reg_left = []\n",
    "threshold_tuned = []\n",
    "\n",
    "for fold in tqdm(range(len(predictions_test))):\n",
    "    #print(fold)\n",
    "    outcome_dict_train = predictions_train[fold]\n",
    "    outcome_dict = predictions_test[fold]\n",
    "\n",
    "    # Calculate policy decision\n",
    "    policy_dict, errors = calc_bayesian_policy(\n",
    "        treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "        conversion_dict=outcome_dict[\"conversion\"],\n",
    "        margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST,\n",
    "        calc_error=True, y=y[outcome_dict[\"idx\"]],\n",
    "        g=g[outcome_dict[\"idx\"]], tau_true=tau_response[outcome_dict[\"idx\"]])\n",
    "\n",
    "    # # Tune threshold for regularization\n",
    "    threshold_dict = tune_gamma(outcome_dict_train[\"treatment_spending\"], outcome_dict_train['prediction_intervals'],\n",
    "                                conversion_dict=outcome_dict_train[\"conversion\"], margin=MARGIN_RATIO,\n",
    "                                contact_cost=0, offer_cost=OFFER_COST, y_true=y[outcome_dict_train[\"idx\"]],\n",
    "                                c_true=c[outcome_dict_train[\"idx\"]], g=g[outcome_dict_train[\"idx\"]],\n",
    "                                prob_treatment=None)\n",
    "    #\n",
    "\n",
    "    reg_policy, errors_reg = calc_bayesian_uncertainty_policy(\n",
    "        treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "        pi_dict=outcome_dict['prediction_intervals'],\n",
    "        conversion_dict=outcome_dict[\"conversion\"],\n",
    "        margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST, gamma_dict=threshold_dict,\n",
    "        tail='left', calc_error=True, y=y[outcome_dict[\"idx\"]],\n",
    "        g=g[outcome_dict[\"idx\"]], tau_true=tau_response[outcome_dict[\"idx\"]])\n",
    "    policy_dict.update(reg_policy)\n",
    "\n",
    "    errors['TOL'].update(errors_reg['TOL'])\n",
    "    errors['RSME'].update(errors_reg['RSME'])\n",
    "    errors['Ratio_test'].update(errors_reg['Ratio_test'])\n",
    "\n",
    "    profit = calc_policy_profit(\n",
    "        policy_dict=policy_dict,\n",
    "        y_true=y[outcome_dict[\"idx\"]], c_true=c[outcome_dict[\"idx\"]], g=g[outcome_dict[\"idx\"]],\n",
    "        margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST)\n",
    "\n",
    "    profit.update(errors)\n",
    "\n",
    "    eval_profit_reg_left.append(profit)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Profit Dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit = pd.concat([pd.DataFrame(x) for x in eval_profit_reg_left], axis=0, keys=range(len(eval_profit_reg_left)))\n",
    "eval_profit.index.rename([\"fold\", \"model\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit = eval_profit.groupby(\"model\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.index = pd.MultiIndex.from_tuples(eval_profit.index.str.split(\"[+]\", expand=True).tolist())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.index.names = [\"Policy\", \"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"gamma\", \"profit\",\n",
    "                           \"ratio_treated\", \"TOL\", \"RSME\", \"Ratio_test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.reset_index(drop=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit = eval_profit.reindex(columns=[\"Policy\", \"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\",\n",
    "                                           \"profit\", \"ratio_treated\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.to_excel(f\"results/{today}_eval_profit_reg.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyze thresholds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# change ordering of dicts\n",
    "tau_by_fold_xbcf = []\n",
    "tau_by_fold_CP = []\n",
    "\n",
    "for folds in threshold_tuned:\n",
    "    list = folds['single-model_hurdle_gbt']['CP_two-model_NN']['single-model_hurdle_gbt']\n",
    "    tau_by_fold_CP.append(list)\n",
    "    list = folds['single-model_hurdle_gbt']['xbcf_outcome_xbcf']['single-model_hurdle_gbt']\n",
    "    tau_by_fold_xbcf.append(list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.mean(tau_by_fold_xbcf))\n",
    "print(np.mean(tau_by_fold_CP))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Uncertainty Evaluation for Regularization Policy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit = pd.concat([pd.DataFrame(x) for x in eval_profit_reg_left], axis=0, keys=range(len(eval_profit_reg_left)))\n",
    "eval_profit.index.rename([\"fold\", \"model\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit = eval_profit.groupby(\"model\").filter(lambda x: True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.index = pd.MultiIndex.from_tuples(eval_profit.index.str.split(\"[+]\", expand=True).tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.index.names = [\"Policy\", \"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Lambda\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.index.names = [\"Fold\", \"Model\", ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit.reset_index(drop=False, inplace=True)\n",
    "eval_profit = eval_profit.reindex(columns=[\"Fold\", \"Model\",\n",
    "                                           \"profit\", \"ratio_treated\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit  #.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PI_model_names = eval_profit['PI_Estimator'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CATE_model = 'xbcf_outcome_xbcf'\n",
    "PI_model = 'xbcf_outcome_xbcf'\n",
    "conversion_model = 'single-model_outcome_gbt'\n",
    "\n",
    "gamma = '0.0'\n",
    "model = str('Bayesian' + '+' + CATE_model + '+' + conversion_model)\n",
    "model2 = str('Regularization' + '+' + CATE_model + '+' + conversion_model + '+' + PI_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CATE_model = 'single-model_hurdle_gbt'\n",
    "conversion_model = 'single-model_hurdle_gbt'\n",
    "PI_model = 'xbcf_outcome_xbcf'\n",
    "\n",
    "gamma = '0.0'\n",
    "model3 = str('Bayesian' + '+' + CATE_model + '+' + conversion_model)\n",
    "model4 = str('Regularization' + '+' + CATE_model + '+' + conversion_model + '+' + PI_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CATE_model = 'two-model_hurdle_gbt'\n",
    "conversion_model = 'two-model_hurdle_gbt'\n",
    "PI_model = 'xbcf_outcome_xbcf'\n",
    "\n",
    "gamma = '0.0'\n",
    "model5 = str('Bayesian' + '+' + CATE_model + '+' + conversion_model)\n",
    "model6 = str('Regularization' + '+' + CATE_model + '+' + conversion_model + '+' + PI_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot = eval_profit[(eval_profit['Model'] == model) | (eval_profit['Model'] == model2)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "treatments = [eval_profit[(eval_profit['Model'] == model)].profit, eval_profit[(eval_profit['Model'] == model2)].profit,\n",
    "              eval_profit[(eval_profit['Model'] == model3)].profit,\n",
    "              eval_profit[(eval_profit['Model'] == model4)].profit,\n",
    "              eval_profit[(eval_profit['Model'] == model5)].profit,\n",
    "              eval_profit[(eval_profit['Model'] == model6)].profit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit[(eval_profit['Model'] == model6)].profit\n",
    "#model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#medians = [None, None, med1, med2]\n",
    "#conf_intervals = [None, None, ci1, ci2]\n",
    "labels = ['XBCF', 'XBCF_*', '1_Hurdle', '1_Hurdle_*', '2_Hurdle', '2_Hurdle_*']\n",
    "fig, ax = plt.subplots()\n",
    "pos = np.arange(len(treatments)) + 1\n",
    "bp = ax.boxplot(treatments, sym='k+', positions=pos, showmeans=True)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlabel('Policies')\n",
    "ax.set_ylabel('Profit')\n",
    "plt.setp(bp['whiskers'], color='k', linestyle='-')\n",
    "plt.setp(bp['fliers'], markersize=3.0)\n",
    "#plt.show()\n",
    "plt.savefig(f\"figures/regularization/uncertainty/{today}_profit_catescaled.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 Sharpe Policy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# number of customers\n",
    "start = 0\n",
    "stop = len(predictions_test[0]['idx'])\n",
    "step = 500\n",
    "\n",
    "float_range_array = np.arange(start, stop, step)  #.round(2)\n",
    "float_range_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe = []\n",
    "for num_customers in float_range_array:  #float_range_array\n",
    "    #eval_profit_sharpe.append(num_customers)\n",
    "    for outcome_dict in predictions_test:\n",
    "        #outcome_dict_train = prediction_dict[\"train\"]\n",
    "        #outcome_dict = prediction_dict[\"test\"]\n",
    "\n",
    "        # Calculate policy decision\n",
    "        policy_dict_order = calc_sharpe_policy(\n",
    "            treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "            pi_dict=outcome_dict['prediction_intervals'],\n",
    "            conversion_dict=outcome_dict[\"conversion\"],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST,\n",
    "            ordering=True)\n",
    "\n",
    "        policy_dict = select_customers(policy_dict_order=policy_dict_order, num_customers=num_customers)\n",
    "\n",
    "        policy, errors = calc_sharpe_policy_error(treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "                                                  pi_dict=outcome_dict['prediction_intervals'],\n",
    "                                                  conversion_dict=outcome_dict[\"conversion\"],\n",
    "                                                  margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST,\n",
    "                                                  ordering=True, calc_error=True, y=y[outcome_dict[\"idx\"]],\n",
    "                                                  g=g[outcome_dict[\"idx\"]], tau_true=tau_response[outcome_dict[\"idx\"]],\n",
    "                                                  policy_dict=policy_dict, num_customers=num_customers)\n",
    "\n",
    "        profit_sharpe = calc_policy_profit(\n",
    "            policy_dict=policy_dict,\n",
    "            y_true=y[outcome_dict[\"idx\"]], c_true=c[outcome_dict[\"idx\"]], g=g[outcome_dict[\"idx\"]],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST)\n",
    "\n",
    "        profit_sharpe.update(errors)\n",
    "\n",
    "        eval_profit_sharpe.append(profit_sharpe)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#np.save(f\"results/sharpe_customers_{today}_errors.npy\", eval_profit_sharpe, allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe_save = eval_profit_sharpe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe = pd.concat([pd.DataFrame(x) for x in eval_profit_sharpe], axis=0,\n",
    "                               keys=range(len(eval_profit_sharpe)))\n",
    "eval_profit_sharpe.index.rename([\"fold\", \"model\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_profit = eval_profit.groupby(\"model\").agg([np.mean, 'sem'])\n",
    "eval_profit_sharpe = eval_profit_sharpe.groupby(\"model\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe.index = pd.MultiIndex.from_tuples(eval_profit_sharpe.index.str.split(\"[+]\", expand=True).tolist())\n",
    "eval_profit_sharpe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_profit.index.names = [\"CATE_Estimator\",\"Conversion_Estimator\",\"PI_Estimator\",\"Sharpe\"]\n",
    "eval_profit_sharpe.index.names = [\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\", \"Customers\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe.reset_index(drop=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe = eval_profit_sharpe.reindex(\n",
    "    columns=[\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "             \"Customers\", \"profit\", \"ratio_treated\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "eval_profit_sharpe.columns = [\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\", \"Customers\", \"profit\",\n",
    "                              \"ratio_treated\", \"TOL\", \"root_mse\", \"Ratio_test\"]\n",
    "eval_profit_sharpe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe.to_excel(f\"results/{today}_eval_profit_sharpe_customers_errors.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe = np.load(f\"results/sharpe_customers_2022-05-20_errors.npy\", allow_pickle=True)\n",
    "eval_profit_sharpe = pd.DataFrame(eval_profit_sharpe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get minimum and maximum profit values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe_vals = np.load(f\"results/sharpe_customers_2022-05-18.npy\", allow_pickle=True)\n",
    "eval_profit_sharpe_vals = pd.concat([pd.DataFrame(x) for x in eval_profit_sharpe_vals], axis=0,\n",
    "                                    keys=range(len(eval_profit_sharpe_vals)))\n",
    "eval_profit_sharpe_vals.index.rename([\"fold\", \"model\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_profit = eval_profit.groupby(\"model\").agg([np.mean, 'sem'])\n",
    "eval_profit_sharpe_vals_min = eval_profit_sharpe_vals.groupby(\"model\").quantile(q=0.05)\n",
    "eval_profit_sharpe_vals_max = eval_profit_sharpe_vals.groupby(\"model\").quantile(q=0.95)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe_vals_min.index = pd.MultiIndex.from_tuples(\n",
    "    eval_profit_sharpe_vals_min.index.str.split(\"[+]\", expand=True).tolist())\n",
    "eval_profit_sharpe_vals_max.index = pd.MultiIndex.from_tuples(\n",
    "    eval_profit_sharpe_vals_max.index.str.split(\"[+]\", expand=True).tolist())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_profit.index.names = [\"CATE_Estimator\",\"Conversion_Estimator\",\"PI_Estimator\",\"Sharpe\"]\n",
    "eval_profit_sharpe_vals_min.index.names = [\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "                                           \"Customers\"]\n",
    "eval_profit_sharpe_vals_max.index.names = [\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "                                           \"Customers\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe_vals_min.reset_index(drop=False, inplace=True)\n",
    "eval_profit_sharpe_vals_max.reset_index(drop=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_sharpe_vals_min = eval_profit_sharpe_vals_min.reindex(\n",
    "    columns=[\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "             \"Customers\", \"profit\", \"ratio_treated\"])\n",
    "eval_profit_sharpe_vals_max = eval_profit_sharpe_vals_max.reindex(\n",
    "    columns=[\"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "             \"Customers\", \"profit\", \"ratio_treated\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare with Analytical Policy for fewer customers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical = []\n",
    "\n",
    "for num_customers in float_range_array:\n",
    "    for outcome_dict in predictions_test:\n",
    "        #outcome_dict_train = prediction_dict[\"train\"]\n",
    "        #outcome_dict = prediction_dict[\"test\"]\n",
    "\n",
    "        # Calculate policy decision: gamma 0 for analytical policy\n",
    "        policy_dict_order = calc_bayesian_uncertainty_policy_fixed_gamma(\n",
    "            treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "            pi_dict=outcome_dict['prediction_intervals'],\n",
    "            conversion_dict=outcome_dict[\"conversion\"],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST, gamma=0,\n",
    "            tail='left', ordering=True)\n",
    "\n",
    "        policy_dict_analytical = select_customers(policy_dict_order=policy_dict_order, num_customers=num_customers)\n",
    "\n",
    "        policy, errors = calc_bayesian_uncertainty_policy_fixed_gamma_error(\n",
    "            treatment_dict=outcome_dict[\"treatment_spending\"],\n",
    "            pi_dict=outcome_dict['prediction_intervals'],\n",
    "            conversion_dict=outcome_dict[\"conversion\"],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST, gamma=0,\n",
    "            ordering=True, calc_error=True, y=y[outcome_dict[\"idx\"]],\n",
    "            g=g[outcome_dict[\"idx\"]], tau_true=tau_response[outcome_dict[\"idx\"]], policy_dict=policy_dict_analytical,\n",
    "            num_customers=num_customers)\n",
    "\n",
    "        profit = calc_policy_profit(\n",
    "            policy_dict=policy_dict_analytical,\n",
    "            y_true=y[outcome_dict[\"idx\"]], c_true=c[outcome_dict[\"idx\"]], g=g[outcome_dict[\"idx\"]],\n",
    "            margin=MARGIN_RATIO, contact_cost=0, offer_cost=OFFER_COST)\n",
    "        profit.update(errors)\n",
    "        eval_profit_analytical.append(profit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical = pd.concat([pd.DataFrame(x) for x in eval_profit_analytical], axis=0,\n",
    "                                   keys=range(len(eval_profit_analytical)))\n",
    "eval_profit_analytical.index.rename([\"fold\", \"model\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_profit = eval_profit.groupby(\"model\").agg([np.mean, 'sem'])\n",
    "eval_profit_analytical = eval_profit_analytical.groupby(\"model\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical.index = pd.MultiIndex.from_tuples(\n",
    "    eval_profit_analytical.index.str.split(\"[+]\", expand=True).tolist())\n",
    "eval_profit_analytical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_profit.index.names = [\"CATE_Estimator\",\"Conversion_Estimator\",\"PI_Estimator\",\"Sharpe\"]\n",
    "eval_profit_analytical.index.names = [\"Policy\", \"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "                                      \"Customers\", \"profit\", \"ratio_treated\", \"TOL\", \"RSME\", \"Ratio_test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical.reset_index(drop=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical = eval_profit_analytical.reindex(\n",
    "    columns=[\"Policy\", \"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "             \"Customers\", \"profit\", \"ratio_treated\", \"TOL\", \"RSME\", \"Ratio_test\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical.to_excel(f\"results/{today}_eval_profit_analytical_customers_errors.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to load up results again\n",
    "eval_profit_analytical = np.load(f\"results/analytical_customers_2022-05-20.npy\", allow_pickle=True)\n",
    "eval_profit_analytical = pd.DataFrame(eval_profit_analytical)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical.columns = [\"Policy\", \"CATE_Estimator\", \"Conversion_Estimator\", \"PI_Estimator\", \"Sharpe\",\n",
    "                                  \"Customers\", \"profit\", \"ratio_treated\", \"TOL\", \"root_mse\", \"Ratio_test\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#np.save(f\"results/analytical_customers_{today}.npy\", eval_profit_analytical, allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PI_model_names = eval_profit_sharpe['PI_Estimator'].unique()\n",
    "PI_model_names = ['Agnostic_QR_two-model', 'xbcf_outcome_xbcf']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Sharpe Policy: Errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#CATE_model ='xbcf_outcome_xbcf'\n",
    "#CATE_model = 'two-model_hurdle_gbt'\n",
    "CATE_model = \"single-model_hurdle_gbt\"\n",
    "#conversion_model = \"single-model_outcome_gbt\"\n",
    "conversion_model = \"Conversion-Rate__\"\n",
    "#conversion_model =  'two-model_hurdle_gbt'\n",
    "#conversion_model = 'single-model_hurdle_gbt'\n",
    "#PI_model = 'Agnostic_QR_two-model_hurdle'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for RSME\n",
    "eval_profit_analytical['Customers'] = eval_profit_analytical['Customers'].astype('int')\n",
    "eval_profit_sharpe['Customers'] = eval_profit_sharpe['Customers'].astype('int')\n",
    "\n",
    "#df_plot = eval_profit_analytical[(eval_profit_analytical['CATE_Estimator']==CATE_model) & (eval_profit_analytical['Conversion_Estimator']==conversion_model)&(eval_profit_analytical['PI_Estimator']=='Agnostic_QR_two-model')].sort_values(by=['Customers'])\n",
    "df_plot = eval_profit_analytical[(eval_profit_analytical['CATE_Estimator'] == CATE_model) & (\n",
    "            eval_profit_analytical['Conversion_Estimator'] == conversion_model) &\n",
    "                                 (eval_profit_analytical['PI_Estimator'] == PI_model)].sort_values(by=['Customers'])\n",
    "data_list = {}\n",
    "for PI_model in PI_model_names:\n",
    "    #df_plot_sharpe = {}\n",
    "    df_plot_sharpe = eval_profit_sharpe[(eval_profit_sharpe['CATE_Estimator'] == CATE_model) & (\n",
    "                eval_profit_sharpe['Conversion_Estimator'] == conversion_model) &\n",
    "                                        (eval_profit_sharpe['PI_Estimator'] == PI_model)].sort_values(by=['Customers'])\n",
    "    name = str(PI_model)\n",
    "    data_list[name] = df_plot_sharpe\n",
    "\n",
    "plt.plot(df_plot.Customers[1:], df_plot.root_mse[1:], label='Analytical')\n",
    "\n",
    "for PI_model in PI_model_names:\n",
    "    plt.plot(data_list[PI_model].Customers, data_list[PI_model].root_mse, alpha=0.5, label=f\"Sharpe+{PI_model[0:22]}\")\n",
    "\n",
    "plt.title(f\"Error for {CATE_model} with {conversion_model}.\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Maximum Number of Customers\")\n",
    "plt.ylabel(\"RSME\")\n",
    "plt.savefig(f\"figures/{today}_sharpe_evaluate_RSME_{CATE_model}_{conversion_model}.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for profit only:\n",
    "eval_profit_analytical['Customers'] = eval_profit_analytical['Customers'].astype('int')\n",
    "eval_profit_sharpe['Customers'] = eval_profit_sharpe['Customers'].astype('int')\n",
    "\n",
    "df_plot = eval_profit_analytical[(eval_profit_analytical['CATE_Estimator'] == CATE_model) & (\n",
    "            eval_profit_analytical['Conversion_Estimator'] == conversion_model)].sort_values(by=['Customers'])\n",
    "\n",
    "data_list = {}\n",
    "for PI_model in PI_model_names:\n",
    "    #df_plot_sharpe = {}\n",
    "    df_plot_sharpe = eval_profit_sharpe[(eval_profit_sharpe['CATE_Estimator'] == CATE_model) & (\n",
    "                eval_profit_sharpe['Conversion_Estimator'] == conversion_model) &\n",
    "                                        (eval_profit_sharpe['PI_Estimator'] == PI_model)].sort_values(by=['Customers'])\n",
    "    name = str(PI_model)\n",
    "    data_list[name] = df_plot_sharpe\n",
    "\n",
    "plt.plot(df_plot.Customers, df_plot.profit, label='Analytical')\n",
    "\n",
    "for PI_model in PI_model_names:\n",
    "    plt.plot(data_list[PI_model].Customers, data_list[PI_model].profit, label=f\"Sharpe+{PI_model[0:22]}\", alpha=0.5)\n",
    "plt.title(f\"Profit for {CATE_model} with {conversion_model}.\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Maximum Number of Customers\")\n",
    "plt.ylabel(\"Profit\")\n",
    "plt.savefig(f\"figures/{today}_sharpe_evaluate_{CATE_model}_{conversion_model}.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots for Sharpe Policy: Profit\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#CATE_model ='xbcf_outcome_xbcf'\n",
    "\n",
    "#conversion_model = 'Conversion-Rate__'\n",
    "#conversion_model = 'single-model_outcome_gbt'\n",
    "#PI_model = 'Agnostic_QR_two-model_hurdle'\n",
    "#CATE_model ='xbcf_outcome_xbcf'\n",
    "#CATE_model = 'two-model_hurdle_gbt'\n",
    "CATE_model = \"single-model_hurdle_gbt\"\n",
    "conversion_model = \"single-model_hurdle_gbt\"\n",
    "#conversion_model = \"single-model_outcome_gbt\"\n",
    "#conversion_model = \"Conversion-Rate__\"\n",
    "#conversion_model =  'two-model_hurdle_gbt'\n",
    "#conversion_model = 'single-model_outcome_gbt'\n",
    "#PI_model = 'Agnostic_QR_two-model_hurdle'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_profit_analytical['Customers'] = eval_profit_analytical['Customers'].astype('int')\n",
    "eval_profit_sharpe['Customers'] = eval_profit_sharpe['Customers'].astype('int')\n",
    "eval_profit_sharpe_vals_min['Customers'] = eval_profit_sharpe_vals_min['Customers'].astype('int')\n",
    "eval_profit_sharpe_vals_max['Customers'] = eval_profit_sharpe_vals_max['Customers'].astype('int')\n",
    "\n",
    "df_plot = eval_profit_analytical[(eval_profit_analytical['CATE_Estimator'] == CATE_model) & (\n",
    "            eval_profit_analytical['Conversion_Estimator'] == conversion_model)].sort_values(by=['Customers'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_list = {}\n",
    "data_list_min = {}\n",
    "data_list_max = {}\n",
    "\n",
    "for PI_model in PI_model_names:\n",
    "    #df_plot_sharpe = {}\n",
    "    df_plot_sharpe = eval_profit_sharpe[(eval_profit_sharpe['CATE_Estimator'] == CATE_model) & (\n",
    "                eval_profit_sharpe['Conversion_Estimator'] == conversion_model) &\n",
    "                                        (eval_profit_sharpe['PI_Estimator'] == PI_model)].sort_values(by=['Customers'])\n",
    "    name = str(PI_model)\n",
    "    data_list[name] = df_plot_sharpe\n",
    "\n",
    "    df_plot_sharpe_min = eval_profit_sharpe_vals_min[(eval_profit_sharpe_vals_min['CATE_Estimator'] == CATE_model) & (\n",
    "                eval_profit_sharpe_vals_min['Conversion_Estimator'] == conversion_model) &\n",
    "                                                     (eval_profit_sharpe_vals_min[\n",
    "                                                          'PI_Estimator'] == PI_model)].sort_values(by=['Customers'])\n",
    "    name = str(PI_model)\n",
    "    data_list_min[name] = df_plot_sharpe_min\n",
    "\n",
    "    df_plot_sharpe_max = eval_profit_sharpe_vals_max[(eval_profit_sharpe_vals_max['CATE_Estimator'] == CATE_model) & (\n",
    "                eval_profit_sharpe_vals_max['Conversion_Estimator'] == conversion_model) &\n",
    "                                                     (eval_profit_sharpe_vals_max[\n",
    "                                                          'PI_Estimator'] == PI_model)].sort_values(by=['Customers'])\n",
    "    name = str(PI_model)\n",
    "    data_list_max[name] = df_plot_sharpe_max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(df_plot.Customers, df_plot.profit, label='Analytical')\n",
    "plt.fill_between(df_plot.Customers, df_plot_sharpe_min.profit, df_plot_sharpe_max.profit\n",
    "                 , edgecolor='darkblue', facecolor='lightblue', alpha=0.5)  #\n",
    "\n",
    "#for PI_model in PI_model_names:\n",
    "plt.plot(data_list[PI_model_names[0]].Customers, data_list[PI_model_names[0]].profit,\n",
    "         label=f\"Sharpe+{PI_model_names[0][0:22]}\", alpha=0.5)\n",
    "plt.fill_between(data_list[PI_model_names[0]].Customers, data_list_min[PI_model_names[0]].profit,\n",
    "                 data_list_max[PI_model_names[0]].profit,\n",
    "                 edgecolor='red', facecolor='orange', alpha=0.3)  # alpha=0.1\n",
    "\n",
    "plt.plot(data_list[PI_model_names[1]].Customers, data_list[PI_model_names[1]].profit,\n",
    "         label=f\"Sharpe+{PI_model_names[1][0:22]}\", alpha=0.5)\n",
    "plt.fill_between(data_list[PI_model_names[1]].Customers, data_list_min[PI_model_names[1]].profit,\n",
    "                 data_list_max[PI_model_names[1]].profit,\n",
    "                 edgecolor=\"green\", facecolor='lightgreen', alpha=0.3)  # alpha=0.1\n",
    "plt.title(f\"Profit for {CATE_model} with {conversion_model}.\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Maximum Number of Customers\")\n",
    "plt.ylabel(\"Profit\")\n",
    "plt.savefig(f\"figures/{today}_sharpe_evaluate_uncertainty_{CATE_model}_{conversion_model}.pdf\",\n",
    "            bbox_inches='tight')\n",
    "plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale PIs for Oracle Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(predictions_test)):\n",
    "    for alpha in [0.05]:\n",
    "        for model in predictions_test[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf']:\n",
    "            print(model)\n",
    "            #print(abs(max(predictions_test[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'])))\n",
    "            predictions_test[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'] =            predictions_test[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'] - abs(\n",
    "                max(predictions_test[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'])) - 1\n",
    "            predictions_train[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'] =            predictions_train[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'] - abs(\n",
    "                max(predictions_train[i]['prediction_intervals'][alpha]['xbcf_outcome_xbcf'][model]['pred_low'])) - 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_test_oracle = [scale_PIs(outcome_dict[\"prediction_intervals\"], tau_response[outcome_dict[\"idx\"]])\n",
    "                     for outcome_dict in predictions_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_train_oracle = [scale_PIs(outcome_dict[\"prediction_intervals\"], tau_response[outcome_dict[\"idx\"]])\n",
    "                      for outcome_dict in predictions_train]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have some scaled i.e. oracle PIs for every model\n",
    "we can use it with our targeting policy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(predictions_test)):\n",
    "    for alpha in [0.05]:\n",
    "        for model in predictions_test[i]['prediction_intervals'][alpha]:\n",
    "            print(model)\n",
    "            if predictions_test[i]['prediction_intervals'][alpha][model] == 'posterior':\n",
    "                pass\n",
    "            else:\n",
    "                predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low'] = scale_test_oracle[i][alpha][model]['best_scaling'][0] * predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low']\n",
    "                predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high'] = scale_test_oracle[i][alpha][model]['best_scaling'][1] * predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(predictions_train)):\n",
    "    for alpha in [0.05]:\n",
    "        for model in predictions_train[i]['prediction_intervals'][alpha]:\n",
    "            print(model)\n",
    "            if predictions_train[i]['prediction_intervals'][alpha][model] == 'posterior':\n",
    "                pass\n",
    "            else:\n",
    "                predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low'] =scale_train_oracle[i][alpha][model]['best_scaling'][0] * predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low']\n",
    "                predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high'] = scale_train_oracle[i][alpha][model]['best_scaling'][1] * predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(f\"results/prediction_test_oracle_cv.npy\", predictions_test, allow_pickle=True)\n",
    "\n",
    "np.save(f\"results/prediction_train_oracle_cv.npy\", predictions_train, allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CATE Scaling:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_train = [\n",
    "    scale_PIs_CATE(outcome_dict_train[\"prediction_intervals\"], treatment_dict=outcome_dict_train[\"treatment_spending\"]\n",
    "                   )\n",
    "    for outcome_dict_train in predictions_train]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_test = [\n",
    "    scale_PIs_CATE(outcome_dict_test[\"prediction_intervals\"], treatment_dict=outcome_dict_test[\"treatment_spending\"]\n",
    "                   )\n",
    "    for outcome_dict_test in predictions_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use it one the PI estimates:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(predictions_test)):\n",
    "    for alpha in [0.05]:\n",
    "        for model in predictions_test[i]['prediction_intervals'][alpha]:\n",
    "            print(model)\n",
    "            if predictions_test[i]['prediction_intervals'][alpha][model] == 'posterior':\n",
    "                pass\n",
    "            else:\n",
    "                predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low'] = scale_test_oracle[i][alpha][model]['best_scaling'][0] *  predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low']\n",
    "                predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high'] = scale_test_oracle[i][alpha][model]['best_scaling'][1] * predictions_test[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(predictions_train)):\n",
    "    for alpha in [0.05]:\n",
    "        for model in predictions_train[i]['prediction_intervals'][alpha]:\n",
    "            print(model)\n",
    "            if predictions_train[i]['prediction_intervals'][alpha][model] == 'posterior':\n",
    "                pass\n",
    "            else:\n",
    "                predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low'] = scale_train_oracle[i][alpha][model]['best_scaling'][0] *  predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_low']\n",
    "                predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high'] = scale_train_oracle[i][alpha][model]['best_scaling'][1] * predictions_train[i]['prediction_intervals'][alpha][model]['quantile_model']['pred_high']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save scaled results:\n",
    "np.save(f\"results/prediction_test_scaled_cv_CATE.npy\", predictions_test, allow_pickle=True)\n",
    "np.save(f\"results/prediction_train_scaled_cv_CATE.npy\", predictions_train, allow_pickle=True)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "uplift",
   "language": "python",
   "display_name": "Python (uplift)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}